{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b><span style='color:#2ae4f5'>|</span> Scenario Generation <a id = \"4\" > </b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements a scenario generation technique for the farmer problem and applies a backward reduction approach for scenario reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pulp import *\n",
    "import random\n",
    "import math\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "<div style=\"color:white;display:fill;border-radius:8px;\n",
    "            background-color:#03112A;font-size:150%;\n",
    "            letter-spacing:1.0px;background-image: url(https://i.imgur.com/GVd0La1.png)\">\n",
    "    <p style=\"padding: 8px;color:white;\"><b><b><span style='color:#2ae4f5'>|</span></b> Inverse Transform Sampling <a id = \"5\" ></b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem that the inverse transform sampling method solves is as follows:\n",
    "\n",
    "- Let $X$ be a random variable whose distribution can be described by the cumulative distribution function $F_x$\n",
    "\n",
    "- We want to generate values of $X$ which are distributed according to this distribution.\n",
    "\n",
    "The inverse transform sampling method works as follows:\n",
    "\n",
    "- **Step 1**: Generate a random number u from the standard uniform distribution in the interval [0, 1] i.e. from $U \\in [0, 1]$.\n",
    "\n",
    "- **Step 2**: Find the generalized inverse of the desired CDF, $F^{-1}_{X}(U)$\n",
    "\n",
    "Ref: https://en.wikipedia.org/wiki/Inverse_transform_sampling\n",
    "\n",
    "\n",
    "Normal Distribution: $F^{-1}(p) = \\mu + \\sqrt2 \\sigma + erf^{-1}(2p-1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_cdf_normal(mean, std_dev, p):\n",
    "    return norm.ppf(p, loc=mean, scale=std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "miu_wheat, sigma_wheat = 2.5, 0.5\n",
    "miu_corn, sigma_corn = 3, 0.6\n",
    "miu_sugar, sigma_sugar = 20, 4\n",
    "num_of_kisi = 3\n",
    "\n",
    "random_list = np.zeros(n - 1)\n",
    "scenarios = np.zeros((n, num_of_kisi))\n",
    "probability = np.zeros(n)\n",
    "\n",
    "# Generating random numbers for n scenarios\n",
    "for i in range(n - 1):\n",
    "\trandom_list[i] = random.random()\n",
    "\n",
    "sorted_numbers = np.sort(random_list)\n",
    "\n",
    "# Generating scenarios from randomNumbers and assign its probability\n",
    "for i, prob in enumerate(sorted_numbers):\n",
    "\tif i == 0:\n",
    "\t\tprobability[i] = prob\n",
    "\t\tscenarios[i][0] = inverse_cdf_normal(mean=miu_wheat, std_dev=sigma_wheat, p=prob/2)\n",
    "\t\tscenarios[i][1] = inverse_cdf_normal(mean=miu_corn, std_dev=sigma_corn, p=prob/2)\n",
    "\t\tscenarios[i][2] = inverse_cdf_normal(mean=miu_sugar, std_dev=sigma_sugar, p=prob/2)\n",
    "  \n",
    "\telif i == n - 2:\n",
    "\t\tprobability[i] = (sorted_numbers[i] - sorted_numbers[i - 1])\n",
    "\t\tcentral_prob = (sorted_numbers[i] + sorted_numbers[i - 1]) / 2\n",
    "\t\tscenarios[i][0] = inverse_cdf_normal(mean=miu_wheat, std_dev=sigma_wheat, p=central_prob)\n",
    "\t\tscenarios[i][1] = inverse_cdf_normal(mean=miu_corn, std_dev=sigma_corn, p=central_prob)\n",
    "\t\tscenarios[i][2] = inverse_cdf_normal(mean=miu_sugar, std_dev=sigma_sugar, p=central_prob)\n",
    "\t\tprobability[n - 1] = (1 - sorted_numbers[n - 2])\n",
    "\t\tcentral_prob = (1 + sorted_numbers[n - 2]) / 2\n",
    "\t\tscenarios[n - 1][0] = inverse_cdf_normal(mean=miu_wheat, std_dev=sigma_wheat, p=central_prob)\n",
    "\t\tscenarios[n - 1][1] = inverse_cdf_normal(mean=miu_corn, std_dev=sigma_corn, p=central_prob)\n",
    "\t\tscenarios[n - 1][2] = inverse_cdf_normal(mean=miu_sugar, std_dev=sigma_sugar, p=central_prob)\n",
    "  \n",
    "\telse:\n",
    "\t\tprobability[i] = (sorted_numbers[i] - sorted_numbers[i - 1])\n",
    "\t\tcentral_prob = (sorted_numbers[i] + sorted_numbers[i - 1]) / 2\n",
    "\t\tscenarios[i][0] = inverse_cdf_normal(mean=miu_wheat, std_dev=sigma_wheat, p=central_prob)\n",
    "\t\tscenarios[i][1] = inverse_cdf_normal(mean=miu_corn, std_dev=sigma_corn, p=central_prob)\n",
    "\t\tscenarios[i][2] = inverse_cdf_normal(mean=miu_sugar, std_dev=sigma_sugar, p=central_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scenario, total_probabilities = scenarios, probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scenario, sum(total_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "<div style=\"color:white;display:fill;border-radius:8px;\n",
    "            background-color:#03112A;font-size:150%;\n",
    "            letter-spacing:1.0px;background-image: url(https://i.imgur.com/GVd0La1.png)\">\n",
    "    <p style=\"padding: 8px;color:white;\"><b><b><span style='color:#2ae4f5'>|</span></b> Scenario Reduction <a id = \"6\" ></b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the index matrices for each scenario\n",
    "total_index = np.zeros(n)\n",
    "for i, scenario in enumerate(total_scenario):\n",
    "    total_index[i] = i    \n",
    "total_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_year = {\"removed_scenarios\": {\"scenario\": [], \"probability\": [], \"index\": []},\n",
    "              \"keeped_scenarios\": {\"scenario\": total_scenario, \"probability\": total_probabilities, \"index\": total_index}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define distance matrix to store distance between scenario i & j\n",
    "minimum_distances = []\n",
    "distance_matrix = np.zeros((n, n))\n",
    "\n",
    "# Calculating each indexes of Distance Matrix\n",
    "for i1, i in enumerate(first_year[\"keeped_scenarios\"][\"scenario\"]):\n",
    "\tfor i2, j in enumerate(first_year[\"keeped_scenarios\"][\"scenario\"]):\n",
    "\t\tif i1 != i2:\n",
    "\t\t\t# Calcualte distances based on Euclidean Distance\n",
    "\t\t\tdistance_matrix[i1][i2] = (math.sqrt(math.pow((i[0] - j[0]), 2) + math.pow((i[1] - j[1]), 2) + math.pow((i[2] - j[2]), 2)))\n",
    "\t\telse:\n",
    "\t\t\tdistance_matrix[i1][i2] = 10000\n",
    "   \n",
    "# print(distance_matrix)\n",
    "\n",
    "# find smallest (Probability * distance)\n",
    "for i, distance in enumerate(distance_matrix):\n",
    "\t# Calculating (probability * distance) for each scenario\n",
    "\tminimum_distances.append(first_year[\"keeped_scenarios\"][\"probability\"][i] * min(distance))\n",
    "\n",
    "min_value = min(minimum_distances)\n",
    "min_index = minimum_distances.index(min_value)\n",
    "first_year[\"removed_scenarios\"][\"scenario\"].append(first_year[\"keeped_scenarios\"][\"scenario\"][min_index])\n",
    "first_year[\"removed_scenarios\"][\"probability\"].append(first_year[\"keeped_scenarios\"][\"probability\"][min_index])\n",
    "first_year[\"removed_scenarios\"][\"index\"].append(first_year[\"keeped_scenarios\"][\"index\"][min_index])\n",
    "first_year[\"keeped_scenarios\"][\"scenario\"] = np.delete(first_year[\"keeped_scenarios\"][\"scenario\"], min_index, axis=0)\n",
    "first_year[\"keeped_scenarios\"][\"probability\"] = np.delete(first_year[\"keeped_scenarios\"][\"probability\"], min_index, axis=0)\n",
    "first_year[\"keeped_scenarios\"][\"index\"] = np.delete(first_year[\"keeped_scenarios\"][\"index\"], min_index)\n",
    "\n",
    "# Define while condition\n",
    "stop_condition = False\n",
    "minimum_distances = []\n",
    "\n",
    "# Stop Condition: # of keeped scenarios <= 15\n",
    "while not stop_condition:\n",
    "\ttotal_distances = []\n",
    "\t# Candidate the keeped scenarios\n",
    "\tfor i, j in enumerate(first_year[\"keeped_scenarios\"][\"scenario\"]):\n",
    "\t\tfirst_year[\"removed_scenarios\"][\"scenario\"].append(j)\n",
    "\t\tfirst_year[\"removed_scenarios\"][\"probability\"].append(first_year[\"keeped_scenarios\"][\"probability\"][i])\n",
    "\t\tfirst_year[\"removed_scenarios\"][\"index\"].append(first_year[\"keeped_scenarios\"][\"index\"][i])\n",
    "\t\tnp.delete(first_year[\"keeped_scenarios\"][\"scenario\"], i, 0)\n",
    "\t\tnp.delete(first_year[\"keeped_scenarios\"][\"probability\"], i, 0)\n",
    "\t\tkeeped_index = np.delete(first_year[\"keeped_scenarios\"][\"index\"], i, 0)\n",
    "\t\t# print(keeped_index)\n",
    "\t\t# Calculating the distance between keeped and removed scenarios\n",
    "\t\tfor i1, k in enumerate(first_year[\"removed_scenarios\"][\"index\"]):\n",
    "\t\t\tdistances = []\n",
    "\t\t\tfor i2, z in enumerate(keeped_index):\n",
    "\t\t\t\tdistances.append(distance_matrix[int(k)][int(z)])\n",
    "\t\t\tminimum_distances.append(first_year[\"removed_scenarios\"][\"probability\"][i1] * min(distances))\n",
    "\t\t# print(minimum_distances)\n",
    "\t\ttotal_distances.append(sum(minimum_distances))\n",
    "\t\t# print(total_distances)\n",
    "\t\tfirst_year[\"removed_scenarios\"][\"scenario\"].pop(-1)\n",
    "\t\tfirst_year[\"removed_scenarios\"][\"probability\"].pop(-1)\n",
    "\t\tfirst_year[\"removed_scenarios\"][\"index\"].pop(-1)\n",
    "\t\tminimum_distances = []\n",
    "\t# Find the best choice for removing\n",
    "\tmin_value = min(total_distances)\n",
    "\tmin_index = total_distances.index(min_value)\n",
    "\n",
    "\t# Check the stop condition\n",
    "\tif len(first_year[\"keeped_scenarios\"][\"scenario\"]) <= 40:\n",
    "\t\tstop_condition = True\n",
    "\telse:\n",
    "\t\tfirst_year[\"removed_scenarios\"][\"scenario\"].append(first_year[\"keeped_scenarios\"][\"scenario\"][min_index])\n",
    "\t\tfirst_year[\"removed_scenarios\"][\"probability\"].append(first_year[\"keeped_scenarios\"][\"probability\"][min_index])\n",
    "\t\tfirst_year[\"removed_scenarios\"][\"index\"].append(first_year[\"keeped_scenarios\"][\"index\"][min_index])\n",
    "\t\tfirst_year[\"keeped_scenarios\"][\"scenario\"] = np.delete(first_year[\"keeped_scenarios\"][\"scenario\"], min_index, 0)\n",
    "\t\tfirst_year[\"keeped_scenarios\"][\"probability\"] = np.delete(first_year[\"keeped_scenarios\"][\"probability\"], min_index, 0)\n",
    "\t\tfirst_year[\"keeped_scenarios\"][\"index\"] = np.delete(first_year[\"keeped_scenarios\"][\"index\"], min_index, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "<div style=\"color:white;display:fill;border-radius:8px;\n",
    "            background-color:#03112A;font-size:150%;\n",
    "            letter-spacing:1.0px;background-image: url(https://i.imgur.com/GVd0La1.png)\">\n",
    "    <p style=\"padding: 8px;color:white;\"><b><b><span style='color:#2ae4f5'>|</span></b> Clustering <a id = \"7\" ></b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(first_year['keeped_scenarios']['probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary to store central represenatative and its probability\n",
    "stage_cluster = {\"cluster\": first_year[\"keeped_scenarios\"][\"scenario\"],\n",
    "\t\t\t\t\t\"probability\": first_year[\"keeped_scenarios\"][\"probability\"]}\n",
    "\n",
    "# Find the best represetative for removed scenario\n",
    "for i1, j in enumerate(first_year[\"removed_scenarios\"][\"scenario\"]):\n",
    "\tdistances = []\n",
    "\tfor i2, k in enumerate(first_year[\"keeped_scenarios\"][\"scenario\"]):\n",
    "\t\tdistance = math.sqrt(math.pow((j[0] - k[0]), 2) + math.pow((j[1] - k[1]), 2) + math.pow((j[2] - k[2]), 2))\n",
    "\t\tdistances.append(distance)\n",
    "\tmin_value = min(distances)\n",
    "\tmin_index = distances.index(min_value)\n",
    "\t# modifying the probability of each cluster\n",
    "\tstage_cluster[\"probability\"][min_index] += first_year[\"removed_scenarios\"][\"probability\"][i1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(first_year['keeped_scenarios']['probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_year['keeped_scenarios']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
